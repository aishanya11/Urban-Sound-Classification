{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Training2.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"s9gZkd_4wypd","colab_type":"code","outputId":"f92d154b-ab7c-449f-bca1-b44593d95fd9","executionInfo":{"status":"ok","timestamp":1555039897414,"user_tz":-330,"elapsed":2495,"user":{"displayName":"Aishanya Singh","photoUrl":"https://lh3.googleusercontent.com/-gtKH7Enlc-I/AAAAAAAAAAI/AAAAAAAABjo/M05RwKqjawU/s64/photo.jpg","userId":"03830106875780112883"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["from keras import models\n","from keras import layers\n","from keras import optimizers\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.callbacks import ModelCheckpoint\n","import matplotlib.pyplot as plt\n","from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n","from keras.models import Sequential, Model\n","from keras.layers import Conv2D, MaxPooling2D\n","from keras import regularizers, optimizers"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"metadata":{"id":"wSYHagynxNkE","colab_type":"code","outputId":"3e8b9c4d-f0cc-40a4-bd80-7dfb2ca8eb41","executionInfo":{"status":"ok","timestamp":1555039960146,"user_tz":-330,"elapsed":65197,"user":{"displayName":"Aishanya Singh","photoUrl":"https://lh3.googleusercontent.com/-gtKH7Enlc-I/AAAAAAAAAAI/AAAAAAAABjo/M05RwKqjawU/s64/photo.jpg","userId":"03830106875780112883"}},"colab":{"base_uri":"https://localhost:8080/","height":123}},"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"metadata":{"id":"UlRcdCc1xNnY","colab_type":"code","outputId":"281a8c52-791d-4b60-a370-c47eebf1f593","executionInfo":{"status":"ok","timestamp":1555039960147,"user_tz":-330,"elapsed":65172,"user":{"displayName":"Aishanya Singh","photoUrl":"https://lh3.googleusercontent.com/-gtKH7Enlc-I/AAAAAAAAAAI/AAAAAAAABjo/M05RwKqjawU/s64/photo.jpg","userId":"03830106875780112883"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["import os\n","os.getcwd()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content'"]},"metadata":{"tags":[]},"execution_count":4}]},{"metadata":{"id":"GULNBe24xNhh","colab_type":"code","outputId":"00e1beba-34a4-4bf6-92ac-25c2cc05da11","executionInfo":{"status":"ok","timestamp":1555039960149,"user_tz":-330,"elapsed":65149,"user":{"displayName":"Aishanya Singh","photoUrl":"https://lh3.googleusercontent.com/-gtKH7Enlc-I/AAAAAAAAAAI/AAAAAAAABjo/M05RwKqjawU/s64/photo.jpg","userId":"03830106875780112883"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["os.listdir()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['.config', 'gdrive', 'sample_data']"]},"metadata":{"tags":[]},"execution_count":5}]},{"metadata":{"id":"GsIi7OYmxgQs","colab_type":"code","colab":{}},"cell_type":"code","source":["root_path = './gdrive/My Drive/OST_Project/working/'"],"execution_count":0,"outputs":[]},{"metadata":{"id":"TCHr1jp-xgTN","colab_type":"code","colab":{}},"cell_type":"code","source":["image_height = 217\n","image_width = 223"],"execution_count":0,"outputs":[]},{"metadata":{"id":"9VKXb6WBxgZQ","colab_type":"code","outputId":"ffdeed5f-ae60-4592-8052-3b1aba17bd86","executionInfo":{"status":"ok","timestamp":1555039960161,"user_tz":-330,"elapsed":65076,"user":{"displayName":"Aishanya Singh","photoUrl":"https://lh3.googleusercontent.com/-gtKH7Enlc-I/AAAAAAAAAAI/AAAAAAAABjo/M05RwKqjawU/s64/photo.jpg","userId":"03830106875780112883"}},"colab":{"base_uri":"https://localhost:8080/","height":1048}},"cell_type":"code","source":["model = models.Sequential()\n","model.add(Conv2D(32, (3, 3), padding='same',\n","                 input_shape=(image_height,image_width,3)))\n","model.add(Activation('relu'))\n","model.add(Conv2D(64, (3, 3)))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","model.add(Conv2D(64, (3, 3), padding='same'))\n","model.add(Activation('relu'))\n","model.add(Conv2D(64, (3, 3)))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.5))\n","model.add(Conv2D(128, (3, 3), padding='same'))\n","model.add(Activation('relu'))\n","model.add(Conv2D(128, (3, 3)))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.5))\n","model.add(Flatten())\n","model.add(Dense(512))\n","model.add(Activation('relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(10, activation='softmax'))\n","model.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_1 (Conv2D)            (None, 217, 223, 32)      896       \n","_________________________________________________________________\n","activation_1 (Activation)    (None, 217, 223, 32)      0         \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 215, 221, 64)      18496     \n","_________________________________________________________________\n","activation_2 (Activation)    (None, 215, 221, 64)      0         \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 107, 110, 64)      0         \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 107, 110, 64)      0         \n","_________________________________________________________________\n","conv2d_3 (Conv2D)            (None, 107, 110, 64)      36928     \n","_________________________________________________________________\n","activation_3 (Activation)    (None, 107, 110, 64)      0         \n","_________________________________________________________________\n","conv2d_4 (Conv2D)            (None, 105, 108, 64)      36928     \n","_________________________________________________________________\n","activation_4 (Activation)    (None, 105, 108, 64)      0         \n","_________________________________________________________________\n","max_pooling2d_2 (MaxPooling2 (None, 52, 54, 64)        0         \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 52, 54, 64)        0         \n","_________________________________________________________________\n","conv2d_5 (Conv2D)            (None, 52, 54, 128)       73856     \n","_________________________________________________________________\n","activation_5 (Activation)    (None, 52, 54, 128)       0         \n","_________________________________________________________________\n","conv2d_6 (Conv2D)            (None, 50, 52, 128)       147584    \n","_________________________________________________________________\n","activation_6 (Activation)    (None, 50, 52, 128)       0         \n","_________________________________________________________________\n","max_pooling2d_3 (MaxPooling2 (None, 25, 26, 128)       0         \n","_________________________________________________________________\n","dropout_3 (Dropout)          (None, 25, 26, 128)       0         \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 83200)             0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 512)               42598912  \n","_________________________________________________________________\n","activation_7 (Activation)    (None, 512)               0         \n","_________________________________________________________________\n","dropout_4 (Dropout)          (None, 512)               0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 10)                5130      \n","=================================================================\n","Total params: 42,918,730\n","Trainable params: 42,918,730\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"metadata":{"id":"1MCjqcNUxgOV","colab_type":"code","colab":{}},"cell_type":"code","source":["train_datagen = ImageDataGenerator(\n","      rescale=1./255)\n","validation_datagen = ImageDataGenerator(rescale=1./255)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"3uD47aDMxgLx","colab_type":"code","colab":{}},"cell_type":"code","source":["train_dir = root_path + 'train'\n","validation_dir = root_path + 'validation'"],"execution_count":0,"outputs":[]},{"metadata":{"id":"RUdXoJJyx_VX","colab_type":"code","outputId":"86d06bff-dd51-41a4-c0f4-cc057a8c2625","executionInfo":{"status":"ok","timestamp":1555039970738,"user_tz":-330,"elapsed":75580,"user":{"displayName":"Aishanya Singh","photoUrl":"https://lh3.googleusercontent.com/-gtKH7Enlc-I/AAAAAAAAAAI/AAAAAAAABjo/M05RwKqjawU/s64/photo.jpg","userId":"03830106875780112883"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"cell_type":"code","source":["# Change the batchsize according to your system RAM\n","train_batchsize = 32\n","val_batchsize = 32\n"," \n","train_generator = train_datagen.flow_from_directory(\n","        train_dir,\n","        target_size=(image_height, image_width),\n","        batch_size=train_batchsize,\n","        class_mode='categorical')\n"," \n","validation_generator = validation_datagen.flow_from_directory(\n","        validation_dir,\n","        target_size=(image_height, image_width),\n","        batch_size=val_batchsize,\n","        class_mode='categorical',\n","        shuffle=False)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Found 7632 images belonging to 10 classes.\n","Found 792 images belonging to 10 classes.\n"],"name":"stdout"}]},{"metadata":{"id":"M7uHgw6nx_b_","colab_type":"code","colab":{}},"cell_type":"code","source":["model.compile(optimizers.rmsprop(lr=0.0005, decay=1e-6),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"pH7Xr1YMyKZH","colab_type":"code","colab":{}},"cell_type":"code","source":["# checkpoint\n","filepath= root_path + \"weights_best4.hdf5\"\n","checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n","callbacks_list = [checkpoint]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"1b8n-vaHyWzP","colab_type":"code","outputId":"c55d5b07-db7c-4195-c154-d6041b4dcf6e","colab":{"base_uri":"https://localhost:8080/","height":4648}},"cell_type":"code","source":["history = model.fit_generator(\n","      train_generator,\n","      steps_per_epoch=train_generator.samples/train_generator.batch_size ,\n","      epochs=100,\n","      validation_data=validation_generator,\n","      validation_steps=validation_generator.samples/validation_generator.batch_size,\n","      callbacks=callbacks_list,\n","      verbose=1)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","Epoch 1/200\n","239/238 [==============================] - 3789s 16s/step - loss: 1.6406 - acc: 0.4253 - val_loss: 1.5693 - val_acc: 0.4697\n","\n","Epoch 00001: val_acc improved from -inf to 0.46970, saving model to ./gdrive/My Drive/OST_Project/working/weights_best4.hdf5\n","Epoch 2/200\n","239/238 [==============================] - 95s 396ms/step - loss: 0.8935 - acc: 0.7127 - val_loss: 1.3547 - val_acc: 0.5682\n","\n","Epoch 00002: val_acc improved from 0.46970 to 0.56818, saving model to ./gdrive/My Drive/OST_Project/working/weights_best4.hdf5\n","Epoch 3/200\n","239/238 [==============================] - 95s 396ms/step - loss: 0.6046 - acc: 0.8016 - val_loss: 1.5957 - val_acc: 0.5985\n","\n","Epoch 00003: val_acc improved from 0.56818 to 0.59848, saving model to ./gdrive/My Drive/OST_Project/working/weights_best4.hdf5\n","Epoch 4/200\n","239/238 [==============================] - 94s 395ms/step - loss: 0.4370 - acc: 0.8628 - val_loss: 1.9729 - val_acc: 0.5884\n","\n","Epoch 00004: val_acc did not improve from 0.59848\n","Epoch 5/200\n","239/238 [==============================] - 94s 395ms/step - loss: 0.3250 - acc: 0.8975 - val_loss: 1.6826 - val_acc: 0.6136\n","\n","Epoch 00005: val_acc improved from 0.59848 to 0.61364, saving model to ./gdrive/My Drive/OST_Project/working/weights_best4.hdf5\n","Epoch 6/200\n","239/238 [==============================] - 94s 395ms/step - loss: 0.2577 - acc: 0.9189 - val_loss: 2.1838 - val_acc: 0.5871\n","\n","Epoch 00006: val_acc did not improve from 0.61364\n","Epoch 7/200\n","239/238 [==============================] - 94s 394ms/step - loss: 0.2249 - acc: 0.9320 - val_loss: 2.0909 - val_acc: 0.6225\n","\n","Epoch 00007: val_acc improved from 0.61364 to 0.62247, saving model to ./gdrive/My Drive/OST_Project/working/weights_best4.hdf5\n","Epoch 8/200\n","239/238 [==============================] - 94s 395ms/step - loss: 0.1763 - acc: 0.9435 - val_loss: 2.1006 - val_acc: 0.5934\n","\n","Epoch 00008: val_acc did not improve from 0.62247\n","Epoch 9/200\n","239/238 [==============================] - 94s 394ms/step - loss: 0.1554 - acc: 0.9502 - val_loss: 2.5280 - val_acc: 0.6111\n","\n","Epoch 00009: val_acc did not improve from 0.62247\n","Epoch 10/200\n","239/238 [==============================] - 94s 394ms/step - loss: 0.1467 - acc: 0.9532 - val_loss: 2.4580 - val_acc: 0.6073\n","\n","Epoch 00010: val_acc did not improve from 0.62247\n","Epoch 11/200\n","239/238 [==============================] - 94s 394ms/step - loss: 0.1365 - acc: 0.9589 - val_loss: 2.5572 - val_acc: 0.6288\n","\n","Epoch 00011: val_acc improved from 0.62247 to 0.62879, saving model to ./gdrive/My Drive/OST_Project/working/weights_best4.hdf5\n","Epoch 12/200\n","239/238 [==============================] - 94s 394ms/step - loss: 0.1285 - acc: 0.9620 - val_loss: 3.4149 - val_acc: 0.5884\n","\n","Epoch 00012: val_acc did not improve from 0.62879\n","Epoch 13/200\n","239/238 [==============================] - 94s 394ms/step - loss: 0.1392 - acc: 0.9621 - val_loss: 2.6515 - val_acc: 0.6313\n","\n","Epoch 00013: val_acc improved from 0.62879 to 0.63131, saving model to ./gdrive/My Drive/OST_Project/working/weights_best4.hdf5\n","Epoch 14/200\n","239/238 [==============================] - 94s 395ms/step - loss: 0.1277 - acc: 0.9652 - val_loss: 3.0116 - val_acc: 0.6111\n","\n","Epoch 00014: val_acc did not improve from 0.63131\n","Epoch 15/200\n","239/238 [==============================] - 94s 394ms/step - loss: 0.1339 - acc: 0.9613 - val_loss: 2.4852 - val_acc: 0.6402\n","\n","Epoch 00015: val_acc improved from 0.63131 to 0.64015, saving model to ./gdrive/My Drive/OST_Project/working/weights_best4.hdf5\n","Epoch 16/200\n","239/238 [==============================] - 94s 394ms/step - loss: 0.1257 - acc: 0.9663 - val_loss: 2.7626 - val_acc: 0.5922\n","\n","Epoch 00016: val_acc did not improve from 0.64015\n","Epoch 17/200\n","239/238 [==============================] - 94s 394ms/step - loss: 0.1111 - acc: 0.9677 - val_loss: 4.0500 - val_acc: 0.6010\n","\n","Epoch 00017: val_acc did not improve from 0.64015\n","Epoch 18/200\n","239/238 [==============================] - 94s 394ms/step - loss: 0.1333 - acc: 0.9640 - val_loss: 2.7837 - val_acc: 0.6515\n","\n","Epoch 00018: val_acc improved from 0.64015 to 0.65152, saving model to ./gdrive/My Drive/OST_Project/working/weights_best4.hdf5\n","Epoch 19/200\n","239/238 [==============================] - 94s 395ms/step - loss: 0.1221 - acc: 0.9659 - val_loss: 2.5814 - val_acc: 0.6338\n","\n","Epoch 00019: val_acc did not improve from 0.65152\n","Epoch 20/200\n","239/238 [==============================] - 94s 394ms/step - loss: 0.1306 - acc: 0.9648 - val_loss: 3.5734 - val_acc: 0.5770\n","\n","Epoch 00020: val_acc did not improve from 0.65152\n","Epoch 21/200\n","239/238 [==============================] - 94s 394ms/step - loss: 0.1219 - acc: 0.9652 - val_loss: 3.3154 - val_acc: 0.6326\n","\n","Epoch 00021: val_acc did not improve from 0.65152\n","Epoch 22/200\n","239/238 [==============================] - 94s 394ms/step - loss: 0.1379 - acc: 0.9660 - val_loss: 3.5144 - val_acc: 0.6124\n","\n","Epoch 00022: val_acc did not improve from 0.65152\n","Epoch 23/200\n","239/238 [==============================] - 94s 392ms/step - loss: 0.1387 - acc: 0.9657 - val_loss: 2.6666 - val_acc: 0.6174\n","\n","Epoch 00023: val_acc did not improve from 0.65152\n","Epoch 24/200\n","239/238 [==============================] - 94s 393ms/step - loss: 0.1402 - acc: 0.9626 - val_loss: 3.3109 - val_acc: 0.5947\n","\n","Epoch 00024: val_acc did not improve from 0.65152\n","Epoch 25/200\n","239/238 [==============================] - 94s 393ms/step - loss: 0.1346 - acc: 0.9637 - val_loss: 5.1076 - val_acc: 0.5606\n","\n","Epoch 00025: val_acc did not improve from 0.65152\n","Epoch 26/200\n","239/238 [==============================] - 94s 393ms/step - loss: 0.1452 - acc: 0.9647 - val_loss: 3.7594 - val_acc: 0.6111\n","\n","Epoch 00026: val_acc did not improve from 0.65152\n","Epoch 27/200\n","239/238 [==============================] - 94s 392ms/step - loss: 0.1354 - acc: 0.9669 - val_loss: 3.8590 - val_acc: 0.5909\n","\n","Epoch 00027: val_acc did not improve from 0.65152\n","Epoch 28/200\n","239/238 [==============================] - 94s 393ms/step - loss: 0.1431 - acc: 0.9644 - val_loss: 3.5550 - val_acc: 0.6250\n","\n","Epoch 00028: val_acc did not improve from 0.65152\n","Epoch 29/200\n","239/238 [==============================] - 94s 393ms/step - loss: 0.1443 - acc: 0.9663 - val_loss: 3.4230 - val_acc: 0.6376\n","\n","Epoch 00029: val_acc did not improve from 0.65152\n","Epoch 30/200\n","239/238 [==============================] - 94s 393ms/step - loss: 0.1399 - acc: 0.9650 - val_loss: 4.2297 - val_acc: 0.6124\n","\n","Epoch 00030: val_acc did not improve from 0.65152\n","Epoch 31/200\n","239/238 [==============================] - 94s 393ms/step - loss: 0.1372 - acc: 0.9651 - val_loss: 3.8294 - val_acc: 0.6136\n","\n","Epoch 00031: val_acc did not improve from 0.65152\n","Epoch 32/200\n","239/238 [==============================] - 94s 392ms/step - loss: 0.1641 - acc: 0.9652 - val_loss: 3.9915 - val_acc: 0.5682\n","\n","Epoch 00032: val_acc did not improve from 0.65152\n","Epoch 33/200\n","239/238 [==============================] - 94s 392ms/step - loss: 0.1546 - acc: 0.9646 - val_loss: 4.3581 - val_acc: 0.5404\n","\n","Epoch 00033: val_acc did not improve from 0.65152\n","Epoch 34/200\n","239/238 [==============================] - 94s 392ms/step - loss: 0.1519 - acc: 0.9625 - val_loss: 4.7463 - val_acc: 0.5442\n","\n","Epoch 00034: val_acc did not improve from 0.65152\n","Epoch 35/200\n","239/238 [==============================] - 94s 392ms/step - loss: 0.1646 - acc: 0.9587 - val_loss: 3.3267 - val_acc: 0.6187\n","\n","Epoch 00035: val_acc did not improve from 0.65152\n","Epoch 36/200\n","239/238 [==============================] - 94s 392ms/step - loss: 0.1751 - acc: 0.9621 - val_loss: 3.6598 - val_acc: 0.5745\n","\n","Epoch 00036: val_acc did not improve from 0.65152\n","Epoch 37/200\n","239/238 [==============================] - 94s 392ms/step - loss: 0.1530 - acc: 0.9652 - val_loss: 3.5668 - val_acc: 0.5871\n","\n","Epoch 00037: val_acc did not improve from 0.65152\n","Epoch 38/200\n","239/238 [==============================] - 94s 392ms/step - loss: 0.1757 - acc: 0.9612 - val_loss: 3.7843 - val_acc: 0.5467\n","\n","Epoch 00038: val_acc did not improve from 0.65152\n","Epoch 39/200\n","239/238 [==============================] - 94s 392ms/step - loss: 0.1598 - acc: 0.9631 - val_loss: 3.5883 - val_acc: 0.6061\n","\n","Epoch 00039: val_acc did not improve from 0.65152\n","Epoch 40/200\n","239/238 [==============================] - 94s 392ms/step - loss: 0.1630 - acc: 0.9631 - val_loss: 4.0687 - val_acc: 0.6111\n","\n","Epoch 00040: val_acc did not improve from 0.65152\n","Epoch 41/200\n","239/238 [==============================] - 94s 392ms/step - loss: 0.1608 - acc: 0.9664 - val_loss: 3.1346 - val_acc: 0.6023\n","\n","Epoch 00041: val_acc did not improve from 0.65152\n","Epoch 42/200\n","239/238 [==============================] - 94s 392ms/step - loss: 0.1569 - acc: 0.9648 - val_loss: 4.0672 - val_acc: 0.5859\n","\n","Epoch 00042: val_acc did not improve from 0.65152\n","Epoch 43/200\n","239/238 [==============================] - 94s 392ms/step - loss: 0.1843 - acc: 0.9609 - val_loss: 3.4360 - val_acc: 0.6427\n","\n","Epoch 00043: val_acc did not improve from 0.65152\n","Epoch 44/200\n","239/238 [==============================] - 94s 392ms/step - loss: 0.1691 - acc: 0.9626 - val_loss: 3.9393 - val_acc: 0.6061\n","\n","Epoch 00044: val_acc did not improve from 0.65152\n","Epoch 45/200\n","239/238 [==============================] - 94s 392ms/step - loss: 0.1908 - acc: 0.9650 - val_loss: 3.6712 - val_acc: 0.6452\n","\n","Epoch 00045: val_acc did not improve from 0.65152\n","Epoch 46/200\n","239/238 [==============================] - 93s 391ms/step - loss: 0.1667 - acc: 0.9659 - val_loss: 3.4645 - val_acc: 0.5934\n","\n","Epoch 00046: val_acc did not improve from 0.65152\n","Epoch 47/200\n","239/238 [==============================] - 93s 391ms/step - loss: 0.1905 - acc: 0.9625 - val_loss: 4.6754 - val_acc: 0.6010\n","\n","Epoch 00047: val_acc did not improve from 0.65152\n","Epoch 48/200\n","239/238 [==============================] - 94s 391ms/step - loss: 0.1826 - acc: 0.9625 - val_loss: 3.3689 - val_acc: 0.6174\n","\n","Epoch 00048: val_acc did not improve from 0.65152\n","Epoch 49/200\n","239/238 [==============================] - 93s 391ms/step - loss: 0.1782 - acc: 0.9670 - val_loss: 4.1510 - val_acc: 0.6313\n","\n","Epoch 00049: val_acc did not improve from 0.65152\n","Epoch 50/200\n","239/238 [==============================] - 94s 391ms/step - loss: 0.1665 - acc: 0.9637 - val_loss: 3.7114 - val_acc: 0.5215\n","\n","Epoch 00050: val_acc did not improve from 0.65152\n","Epoch 51/200\n","239/238 [==============================] - 94s 392ms/step - loss: 0.1628 - acc: 0.9630 - val_loss: 4.0228 - val_acc: 0.5606\n","\n","Epoch 00051: val_acc did not improve from 0.65152\n","Epoch 52/200\n","239/238 [==============================] - 93s 391ms/step - loss: 0.1632 - acc: 0.9670 - val_loss: 5.1529 - val_acc: 0.5758\n","\n","Epoch 00052: val_acc did not improve from 0.65152\n","Epoch 53/200\n","239/238 [==============================] - 94s 391ms/step - loss: 0.1864 - acc: 0.9629 - val_loss: 4.6571 - val_acc: 0.6225\n","\n","Epoch 00053: val_acc did not improve from 0.65152\n","Epoch 54/200\n","239/238 [==============================] - 94s 392ms/step - loss: 0.1814 - acc: 0.9661 - val_loss: 4.6955 - val_acc: 0.6263\n","\n","Epoch 00054: val_acc did not improve from 0.65152\n","Epoch 55/200\n","239/238 [==============================] - 94s 392ms/step - loss: 0.1858 - acc: 0.9670 - val_loss: 3.6671 - val_acc: 0.6402\n","\n","Epoch 00055: val_acc did not improve from 0.65152\n","Epoch 56/200\n","239/238 [==============================] - 94s 392ms/step - loss: 0.2033 - acc: 0.9640 - val_loss: 3.8760 - val_acc: 0.6212\n","\n","Epoch 00056: val_acc did not improve from 0.65152\n","Epoch 57/200\n","239/238 [==============================] - 94s 392ms/step - loss: 0.2096 - acc: 0.9606 - val_loss: 3.6027 - val_acc: 0.5707\n","\n","Epoch 00057: val_acc did not improve from 0.65152\n","Epoch 58/200\n","239/238 [==============================] - 94s 393ms/step - loss: 0.1761 - acc: 0.9659 - val_loss: 4.1774 - val_acc: 0.5164\n","\n","Epoch 00058: val_acc did not improve from 0.65152\n","Epoch 59/200\n","239/238 [==============================] - 94s 393ms/step - loss: 0.1792 - acc: 0.9651 - val_loss: 4.3871 - val_acc: 0.6364\n","\n","Epoch 00059: val_acc did not improve from 0.65152\n","Epoch 60/200\n","239/238 [==============================] - 94s 393ms/step - loss: 0.1831 - acc: 0.9640 - val_loss: 4.4323 - val_acc: 0.6275\n","\n","Epoch 00060: val_acc did not improve from 0.65152\n","Epoch 61/200\n","239/238 [==============================] - 94s 393ms/step - loss: 0.1757 - acc: 0.9657 - val_loss: 4.0002 - val_acc: 0.5997\n","\n","Epoch 00061: val_acc did not improve from 0.65152\n","Epoch 62/200\n","239/238 [==============================] - 94s 393ms/step - loss: 0.1753 - acc: 0.9685 - val_loss: 3.5842 - val_acc: 0.5896\n","\n","Epoch 00062: val_acc did not improve from 0.65152\n","Epoch 63/200\n","239/238 [==============================] - 94s 392ms/step - loss: 0.1585 - acc: 0.9697 - val_loss: 2.3205 - val_acc: 0.5745\n","\n","Epoch 00063: val_acc did not improve from 0.65152\n","Epoch 64/200\n","239/238 [==============================] - 94s 393ms/step - loss: 0.2066 - acc: 0.9629 - val_loss: 4.1186 - val_acc: 0.6035\n","\n","Epoch 00064: val_acc did not improve from 0.65152\n","Epoch 65/200\n","239/238 [==============================] - 94s 392ms/step - loss: 0.1981 - acc: 0.9626 - val_loss: 3.3050 - val_acc: 0.5795\n","\n","Epoch 00065: val_acc did not improve from 0.65152\n","Epoch 66/200\n","239/238 [==============================] - 93s 391ms/step - loss: 0.1818 - acc: 0.9627 - val_loss: 1.9605 - val_acc: 0.4482\n","\n","Epoch 00066: val_acc did not improve from 0.65152\n","Epoch 67/200\n","  3/238 [..............................] - ETA: 1:30 - loss: 0.3691 - acc: 0.9167"],"name":"stdout"}]},{"metadata":{"id":"-_s6TWQUyXLM","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"qgzPbEwdf0Dh","colab_type":"code","colab":{}},"cell_type":"code","source":["acc = history.history['acc']\n","val_acc = history.history['val_acc']\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n"," \n","epochs = range(len(acc))\n"," \n","plt.plot(epochs, acc, 'b', label='Training acc')\n","plt.plot(epochs, val_acc, 'r', label='Validation acc')\n","plt.title('Training and validation accuracy')\n","plt.legend()\n"," \n","plt.figure()\n"," \n","plt.plot(epochs, loss, 'b', label='Training loss')\n","plt.plot(epochs, val_loss, 'r', label='Validation loss')\n","plt.title('Training and validation loss')\n","plt.legend()\n"," \n","plt.show()"],"execution_count":0,"outputs":[]}]}